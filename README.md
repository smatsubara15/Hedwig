# Hedwig.AI <img width="119" alt="image" src="https://github.com/smatsubara15/Hedwig/assets/72986557/c3f5eebf-c739-44c5-a55c-267f1bac75cd">

An LLM-based administrative assistant that mimics user writing styles and pre-writes email replies for executives, boosting professional and personal productivity by up to 25%


## Project Motivation 
Professionals get hundreds of emails a day:
* Many go unread
* Not organized or prioritized
* Can result in missing important Tax/Federal/Bank Statement Docs

Busy professionals may take a long time to respond to all these emails, and the worry of having to respond can be very stressful. This is further marred by subpar Quality of responses and workstream delays.

## How can Hedwig can help? 
Being an LLM-powered administrative assistant, Hedwing handles the following:
* Pre-writes emails for users according to their personal writing styles
* Picks out relevant emails from the past emails of the user
* Gains context around the incoming email from previous responses 
* Identifies relationship between sender and responder to craft responses
* Ensure data security by storing within existing organizational infrastructure

## Project Development
###  Table of Contents

1. [Concept Overview](#introduction)
2. [Data Overview](#data_overview)
3. [Personalization Framework](#personalization)
5. [Prompt Fine-Tuning](#prompt)
6. [Model Fine-Tuning](#model)
7. [Credits](#acknowledgments)


## 1. Concept Overview <a name="introduction"></a>

The single token of data in our analysis is an email-reply pair. Any email-reply pair can be divided into three elements:
* Global Context
* Local Context
* Pair Style Relationship

Using a proprietary personalization framework, Hedwig aims to tap these 3 concepts while using an LLM to reply to any incoming email 

<img width="1138" alt="image" src="https://github.com/smatsubara15/Hedwig/assets/72986557/5fdd8156-9a11-415a-9df1-196aad945956">



## 2. Data Overview <a name="data_overview"></a>

### 2A - Enron Dataset
The Enron email dataset was used for project development. This email dataset contains approximately **500,000 emails** generated by employees of the Enron Corporation. It was obtained by the Federal Energy Regulatory Commission during its investigation of Enron's collapse. 


The original data was obtained has highly dense json files. 
<img width="916" alt="image" src="https://github.com/smatsubara15/Hedwig/assets/72986557/a6deceec-9092-42ed-8eb6-12e4d7dda0b1">

For our purpose, we cleaned and transmuted the data to build message-reply pairs using the following rules:
* Emails with the same subject and sender-recipient pair were grouped into threads
* Rather than focussing on an email, an email-reply conversation was emphasized
* Empty emails, or emails with just emojis/attachments were removed

**~25000 message** reply conversations were identified, which became our modeling dataset
<img width="897" alt="image" src="https://github.com/smatsubara15/Hedwig/assets/72986557/c0ccbc0f-abfa-4675-bbc9-3cc84c8521d7">

### 2B - Human Verification Data
We used close to 250 of personal emails to mimic a local testing environment for our tool.
This helps us further refine our prompts and add human context to our analysis

## 3. Personalization Framework <a name="personalization"></a>
We present a modular framework to embed personalization elements in each step of your email generation 

<img width="978" alt="image" src="https://github.com/smatsubara15/Hedwig/assets/72986557/ecef8894-ad3f-4d6d-bea0-33d020ce098b">

### Level 1 â€“ Global Context

