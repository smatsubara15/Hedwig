{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f886575-cf96-4f7c-a334-3b6d61a9761c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (23.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.1.2\n",
      "    Uninstalling pip-23.1.2:\n",
      "      Successfully uninstalled pip-23.1.2\n",
      "Successfully installed pip-23.2.1\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n",
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/1e/9f/385c25502f437686e4aa715969e5eaf5c2cb5e5ffa7c5cdd52f3c6ae967a/openai-0.28.1-py3-none-any.whl.metadata\n",
      "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from openai) (2.29.0)\n",
      "Requirement already satisfied: tqdm in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from aiohttp->openai) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from aiohttp->openai) (1.2.0)\n",
      "Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "Successfully installed openai-0.28.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install python-dotenv\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b47a560-d271-4df0-b8f2-9bf9f680118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc10e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a9a95db-9797-4291-9d3f-2350fe7ba99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edeca1e6-8920-4f49-92a2-173e9ba37705",
   "metadata": {},
   "source": [
    "## Chat API: OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "609fc6ef-296c-4f4e-b114-f99970b2ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=llm_model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0815730d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion('Hi')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0dfb79f3-475f-4e10-8167-20ead3e160aa",
   "metadata": {},
   "source": [
    "## Chat API : Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8c467aa-5dcb-4c60-a1d6-73f2710a1f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (0.0.306)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from langchain) (3.8.3)\n",
      "Requirement already satisfied: anyio<4.0 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.38 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from langchain) (0.0.41)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from langchain) (2.29.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (4.6.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/kshitijmittal/opt/anaconda3/envs/TENSF/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1faf4a43-63ed-4df9-a8b8-4b408df574e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade langchain\n",
    "import langchain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "282cc202-ad0a-45af-b2b8-9e909f766029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo-0301', temperature=0.0, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model, openai_api_key='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')\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce323ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39141719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['style', 'text'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n'))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cb93f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt\n",
    "# prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e5f4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b0de219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)\n",
    "\n",
    "customer_messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68de554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e381ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm really frustrated that my blender lid flew off and made a mess of my kitchen walls with smoothie. To add to my frustration, the warranty doesn't cover the cost of cleaning up my kitchen. Can you please help me out, friend?\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_response.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa89b7fd",
   "metadata": {},
   "source": [
    "## Data - LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d0c120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPUs: 8\n",
      "INFO: Pandarallel will run on 7 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#pip install pandarallel\n",
    "import multiprocessing\n",
    "\n",
    "num_processors = multiprocessing.cpu_count()\n",
    "print(f'Available CPUs: {num_processors}')\n",
    "\n",
    "import pandarallel\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=num_processors-1, use_memory_fs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5366c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>subject</th>\n",
       "      <th>thread</th>\n",
       "      <th>sender</th>\n",
       "      <th>recipient</th>\n",
       "      <th>message</th>\n",
       "      <th>reply_time</th>\n",
       "      <th>reply_sender</th>\n",
       "      <th>reply_recipient</th>\n",
       "      <th>reply_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1999-06-09 04:18:00-07:00</td>\n",
       "      <td>RE: test</td>\n",
       "      <td>2</td>\n",
       "      <td>5552</td>\n",
       "      <td>[40034]</td>\n",
       "      <td>How about this Friday ? Julie has not left yet...</td>\n",
       "      <td>1999-06-09 08:06:00-07:00</td>\n",
       "      <td>40034</td>\n",
       "      <td>[5552]</td>\n",
       "      <td>when? how are you and your family? is julie go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1999-06-09 08:06:00-07:00</td>\n",
       "      <td>RE: test</td>\n",
       "      <td>2</td>\n",
       "      <td>40034</td>\n",
       "      <td>[5552]</td>\n",
       "      <td>when? how are you and your family? is julie go...</td>\n",
       "      <td>1999-06-10 03:54:00-07:00</td>\n",
       "      <td>5552</td>\n",
       "      <td>[40034]</td>\n",
       "      <td>Today is bad. Tommorrow I will call you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1999-06-09 08:06:00-07:00</td>\n",
       "      <td>RE: test</td>\n",
       "      <td>2</td>\n",
       "      <td>40034</td>\n",
       "      <td>[5552]</td>\n",
       "      <td>when? how are you and your family? is julie go...</td>\n",
       "      <td>1999-11-23 01:38:00-08:00</td>\n",
       "      <td>5552</td>\n",
       "      <td>[40034]</td>\n",
       "      <td>Do you have lunch plans today?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1999-06-09 08:06:00-07:00</td>\n",
       "      <td>RE: test</td>\n",
       "      <td>2</td>\n",
       "      <td>40034</td>\n",
       "      <td>[5552]</td>\n",
       "      <td>when? how are you and your family? is julie go...</td>\n",
       "      <td>1999-11-23 03:13:00-08:00</td>\n",
       "      <td>5552</td>\n",
       "      <td>[40034]</td>\n",
       "      <td>Really? I'd feel like a mooch. Lets have lunch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1999-06-09 08:06:00-07:00</td>\n",
       "      <td>RE: test</td>\n",
       "      <td>2</td>\n",
       "      <td>40034</td>\n",
       "      <td>[5552]</td>\n",
       "      <td>when? how are you and your family? is julie go...</td>\n",
       "      <td>1999-11-23 03:58:00-08:00</td>\n",
       "      <td>5552</td>\n",
       "      <td>[40034]</td>\n",
       "      <td>Tues.is good. I'll call you.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       time   subject  thread  sender recipient  \\\n",
       "0           0  1999-06-09 04:18:00-07:00  RE: test       2    5552   [40034]   \n",
       "1           1  1999-06-09 08:06:00-07:00  RE: test       2   40034    [5552]   \n",
       "2           2  1999-06-09 08:06:00-07:00  RE: test       2   40034    [5552]   \n",
       "3           3  1999-06-09 08:06:00-07:00  RE: test       2   40034    [5552]   \n",
       "4           4  1999-06-09 08:06:00-07:00  RE: test       2   40034    [5552]   \n",
       "\n",
       "                                             message  \\\n",
       "0  How about this Friday ? Julie has not left yet...   \n",
       "1  when? how are you and your family? is julie go...   \n",
       "2  when? how are you and your family? is julie go...   \n",
       "3  when? how are you and your family? is julie go...   \n",
       "4  when? how are you and your family? is julie go...   \n",
       "\n",
       "                  reply_time  reply_sender reply_recipient  \\\n",
       "0  1999-06-09 08:06:00-07:00         40034          [5552]   \n",
       "1  1999-06-10 03:54:00-07:00          5552         [40034]   \n",
       "2  1999-11-23 01:38:00-08:00          5552         [40034]   \n",
       "3  1999-11-23 03:13:00-08:00          5552         [40034]   \n",
       "4  1999-11-23 03:58:00-08:00          5552         [40034]   \n",
       "\n",
       "                                       reply_message  \n",
       "0  when? how are you and your family? is julie go...  \n",
       "1           Today is bad. Tommorrow I will call you.  \n",
       "2                     Do you have lunch plans today?  \n",
       "3  Really? I'd feel like a mooch. Lets have lunch...  \n",
       "4                       Tues.is good. I'll call you.  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_messages=pd.read_csv('/Users/kshitijmittal/Documents/UChicago Acad/Hedwig_AI/Hedwig/00_Data/data_message_reply_pairs_cleaned.csv', parse_dates=['time'])\n",
    "df_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff9881be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96bf4c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo-0301', temperature=0.1, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=ChatOpenAI(temperature=0.1, model=llm_model, openai_api_key='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')\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e501f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['email'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['email'], template='Create a response to the following email in a professional and concise manner: {email}'))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_string=\"\"\"Create a response to the following email in a professional and concise manner: {email}\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template=template_string)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf76d589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=ChatPromptTemplate(input_variables=['email'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['email'], template='Create a response to the following email in a professional and concise manner: {email}'))]), llm=ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo-0301', temperature=0.1, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy=''))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain=LLMChain(llm=llm, prompt=prompt_template)\n",
    "llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c59416c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-3uPIm3xy4QJopNFYHTe9obWT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dear [Name],\\n\\nThank you for your email. I have received your request to forward the e-ticket for Kevin Hyatt to ECN 1334. I will be happy to assist you with this.\\n\\nPlease provide me with the necessary details such as the booking reference number and the email address associated with the booking. Once I have this information, I will promptly forward the e-ticket to the requested email address.\\n\\nThank you for your cooperation. Please let me know if you have any further questions or concerns.\\n\\nBest regards,\\n\\n[Your Name]'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email='pls forward eticket for Kevin Hyatt to ECN 1334. thx'\n",
    "llm_chain.run(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3dbdd5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dear Kevin,\\n\\nThank you for your interest in sponsoring and shopping for a child. We appreciate your generosity and willingness to make a difference in a child's life.\\n\\nTo get started, please contact our sponsorship department at [insert contact information]. They will provide you with all the necessary information and guide you through the process of selecting a child to sponsor and shop for.\\n\\nThank you again for your support.\\n\\nBest regards,\\n\\n[Your Name]\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email='Kevin   I would like to sponsor and shop for a child. Who should I contact?'\n",
    "llm_chain.run(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48acfd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-3uPIm3xy4QJopNFYHTe9obWT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-3uPIm3xy4QJopNFYHTe9obWT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-3uPIm3xy4QJopNFYHTe9obWT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-3uPIm3xy4QJopNFYHTe9obWT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dear Larry,\\n\\nI hope this email finds you well. I received your message and wanted to confirm that I am able to receive and respond to emails. Please let me know if there is anything specific you need assistance with.\\n\\nBest regards,\\n[Your Name]'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run(df_messages.message[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7477e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list=[]\n",
    "for x in range(3,6):\n",
    "    response_list.append(llm_chain.run(df_messages.message[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "260589f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dear [Name],\\n\\nThank you for your email. To answer your questions, I am doing well, and my family is doing great. As for Julie, she is no longer with our company. \\n\\nPlease let me know if you have any further questions or concerns.\\n\\nBest regards,\\n[Your Name]',\n",
       " 'Dear [Name],\\n\\nThank you for your email. To answer your questions, my family and I are doing well, thank you for asking. As for Julie, she is no longer with our company. \\n\\nIf you have any further questions or concerns, please do not hesitate to reach out.\\n\\nBest regards, \\n[Your Name]',\n",
       " \"Dear [Name],\\n\\nThank you for your email. I'm glad to hear that you were able to sit in on some of Candis' classes. I'm sorry we missed each other, but I look forward to meeting you during Open House. If you have any questions or concerns in the meantime, please don't hesitate to reach out.\\n\\nBest regards,\\n[Your Name]\"]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_list"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m107"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
