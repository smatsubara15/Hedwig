{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28d286b2",
   "metadata": {},
   "source": [
    "# **LangChain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f886575-cf96-4f7c-a334-3b6d61a9761c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.2.1)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install python-dotenv\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b47a560-d271-4df0-b8f2-9bf9f680118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# openai.api_key  = os.getenv('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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc10e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.api_key='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a9a95db-9797-4291-9d3f-2350fe7ba99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"codechat-bison\"\n",
    "else:\n",
    "    llm_model = \"codechat-bison\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeca1e6-8920-4f49-92a2-173e9ba37705",
   "metadata": {},
   "source": [
    "## Chat API: OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "609fc6ef-296c-4f4e-b114-f99970b2ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=llm_model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0815730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_completion('Hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb79f3-475f-4e10-8167-20ead3e160aa",
   "metadata": {},
   "source": [
    "## Chat API : Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8c467aa-5dcb-4c60-a1d6-73f2710a1f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.0.310)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: anyio<4.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.40 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.43)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1faf4a43-63ed-4df9-a8b8-4b408df574e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade langchain\n",
    "import langchain\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chat_models import ChatVertexAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "282cc202-ad0a-45af-b2b8-9e909f766029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 03:51:27.821562: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-09 03:51:28.649097: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-10-09 03:51:28.649216: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-10-09 03:51:28.649225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatVertexAI(client=<vertexai.preview.language_models._PreviewChatModel object at 0x7f619892ba90>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "chat = ChatVertexAI(temperature=0.0, model=llm_model)\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce323ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "39141719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['style', 'text'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n'))])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2cb93f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt\n",
    "# prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9e5f4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1b0de219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)\n",
    "\n",
    "customer_messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "68de554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8e381ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa89b7fd",
   "metadata": {},
   "source": [
    "## Data - LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9d0c120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandarallel in /opt/conda/lib/python3.10/site-packages (1.6.5)\n",
      "Requirement already satisfied: dill>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from pandarallel) (0.3.1.1)\n",
      "Requirement already satisfied: pandas>=1 in /opt/conda/lib/python3.10/site-packages (from pandarallel) (2.0.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from pandarallel) (5.9.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1->pandarallel) (1.16.0)\n",
      "Available CPUs: 4\n",
      "INFO: Pandarallel will run on 3 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "!pip install pandarallel\n",
    "import multiprocessing\n",
    "\n",
    "num_processors = multiprocessing.cpu_count()\n",
    "print(f'Available CPUs: {num_processors}')\n",
    "\n",
    "import pandarallel\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=num_processors-1, use_memory_fs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d5366c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>subject</th>\n",
       "      <th>thread</th>\n",
       "      <th>sender</th>\n",
       "      <th>recipient</th>\n",
       "      <th>message</th>\n",
       "      <th>reply_time</th>\n",
       "      <th>reply_sender</th>\n",
       "      <th>reply_recipient</th>\n",
       "      <th>reply_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1999-06-09 04:18:00-07:00</td>\n",
       "      <td>RE: test</td>\n",
       "      <td>2</td>\n",
       "      <td>5552</td>\n",
       "      <td>[40034]</td>\n",
       "      <td>How about this Friday ? Julie has not left yet...</td>\n",
       "      <td>1999-06-09 08:06:00-07:00</td>\n",
       "      <td>40034</td>\n",
       "      <td>[5552]</td>\n",
       "      <td>when? how are you and your family? is julie go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1999-06-09 08:06:00-07:00</td>\n",
       "      <td>RE: test</td>\n",
       "      <td>2</td>\n",
       "      <td>40034</td>\n",
       "      <td>[5552]</td>\n",
       "      <td>when? how are you and your family? is julie go...</td>\n",
       "      <td>1999-06-10 03:54:00-07:00</td>\n",
       "      <td>5552</td>\n",
       "      <td>[40034]</td>\n",
       "      <td>Today is bad. Tommorrow I will call you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1999-06-09 08:06:00-07:00</td>\n",
       "      <td>RE: test</td>\n",
       "      <td>2</td>\n",
       "      <td>40034</td>\n",
       "      <td>[5552]</td>\n",
       "      <td>when? how are you and your family? is julie go...</td>\n",
       "      <td>1999-11-23 01:38:00-08:00</td>\n",
       "      <td>5552</td>\n",
       "      <td>[40034]</td>\n",
       "      <td>Do you have lunch plans today?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1999-06-09 08:06:00-07:00</td>\n",
       "      <td>RE: test</td>\n",
       "      <td>2</td>\n",
       "      <td>40034</td>\n",
       "      <td>[5552]</td>\n",
       "      <td>when? how are you and your family? is julie go...</td>\n",
       "      <td>1999-11-23 03:13:00-08:00</td>\n",
       "      <td>5552</td>\n",
       "      <td>[40034]</td>\n",
       "      <td>Really? I'd feel like a mooch. Lets have lunch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1999-06-09 08:06:00-07:00</td>\n",
       "      <td>RE: test</td>\n",
       "      <td>2</td>\n",
       "      <td>40034</td>\n",
       "      <td>[5552]</td>\n",
       "      <td>when? how are you and your family? is julie go...</td>\n",
       "      <td>1999-11-23 03:58:00-08:00</td>\n",
       "      <td>5552</td>\n",
       "      <td>[40034]</td>\n",
       "      <td>Tues.is good. I'll call you.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       time   subject  thread  sender recipient  \\\n",
       "0           0  1999-06-09 04:18:00-07:00  RE: test       2    5552   [40034]   \n",
       "1           1  1999-06-09 08:06:00-07:00  RE: test       2   40034    [5552]   \n",
       "2           2  1999-06-09 08:06:00-07:00  RE: test       2   40034    [5552]   \n",
       "3           3  1999-06-09 08:06:00-07:00  RE: test       2   40034    [5552]   \n",
       "4           4  1999-06-09 08:06:00-07:00  RE: test       2   40034    [5552]   \n",
       "\n",
       "                                             message  \\\n",
       "0  How about this Friday ? Julie has not left yet...   \n",
       "1  when? how are you and your family? is julie go...   \n",
       "2  when? how are you and your family? is julie go...   \n",
       "3  when? how are you and your family? is julie go...   \n",
       "4  when? how are you and your family? is julie go...   \n",
       "\n",
       "                  reply_time  reply_sender reply_recipient  \\\n",
       "0  1999-06-09 08:06:00-07:00         40034          [5552]   \n",
       "1  1999-06-10 03:54:00-07:00          5552         [40034]   \n",
       "2  1999-11-23 01:38:00-08:00          5552         [40034]   \n",
       "3  1999-11-23 03:13:00-08:00          5552         [40034]   \n",
       "4  1999-11-23 03:58:00-08:00          5552         [40034]   \n",
       "\n",
       "                                       reply_message  \n",
       "0  when? how are you and your family? is julie go...  \n",
       "1           Today is bad. Tommorrow I will call you.  \n",
       "2                     Do you have lunch plans today?  \n",
       "3  Really? I'd feel like a mooch. Lets have lunch...  \n",
       "4                       Tues.is good. I'll call you.  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_messages=pd.read_csv('gs://user-scripts-msca310019-capstone-49b3/data/data_message_reply_pairs_cleaned.csv', parse_dates=['time'])\n",
    "df_messages.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ff9881be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "96bf4c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatVertexAI(client=<vertexai.preview.language_models._PreviewChatModel object at 0x7f12df7cfa30>, temperature=0.1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=ChatVertexAI(temperature=0.1, model=llm_model)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9e501f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['email'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['email'], template='Create a response to the following email in a professional and concise manner: {email}'))])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_string=\"\"\"Create a response to the following email in a professional and concise manner: {email}\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template=template_string)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cf76d589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=ChatPromptTemplate(input_variables=['email'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['email'], template='Create a response to the following email in a professional and concise manner: {email}'))]), llm=ChatVertexAI(client=<vertexai.preview.language_models._PreviewChatModel object at 0x7f12df7cfa30>, temperature=0.1))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain=LLMChain(llm=llm, prompt=prompt_template)\n",
    "llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c59416c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nThank you for your email. \\n\\nI have forwarded Kevin Hyatt's e-ticket to ECN 1334. \\n\\nPlease let me know if you have any other questions. \\n\\nThank you, \\n\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email='pls forward eticket for Kevin Hyatt to ECN 1334. thx'\n",
    "llm_chain.run(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3dbdd5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nThank you for your interest in sponsoring a child through our organization. We are always looking for compassionate and caring individuals to help make a difference in the lives of children in need.\\n\\nTo get started, please contact our Sponsorship Coordinator, John Smith, at [email protected] or call him at 1-800-555-1212. He will be happy to answer any questions you have and help you through the sponsorship process.\\n\\nWe look forward to hearing from you soon and thank you again for your interest in helping a child in need.\\n\\nSincerely,\\n\\n[Your Name]'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email='Kevin   I would like to sponsor and shop for a child. Who should I contact?'\n",
    "llm_chain.run(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "48acfd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hey Larry, \\n\\nI'm checking your email. If you get this, please send me an email back. \\n\\nThanks, \\n[[your name]]\\n\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run(df_messages.message[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7477e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list=[]\n",
    "for x in range(3,10):\n",
    "    response_list.append(llm_chain.run(df_messages.message[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "260589f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Hello, \\n\\nThank you for your email. \\n\\nI am well, thank you for asking. My family is also doing well. \\n\\nJulie is no longer with us. \\n\\nWhen would you like to meet? \\n\\nBest, \\n',\n",
       " ' Hello, \\n\\nThank you for your email. \\n\\nI am well, thank you for asking. My family is also doing well. \\n\\nJulie is no longer with us. \\n\\nWhen would you like to meet? \\n\\nBest, \\n',\n",
       " \" Hi, \\n\\nThank you for your email. I appreciate you keeping me updated on what's going on. I was at the school yesterday sitting in on some of Candis' classes, but unfortunately I didn't get to see you. Hopefully I will be able to meet you during Open House. \\n\\nThanks again,\\n\",\n",
       " ' Hello Larry, \\n\\nI am currently checking my emails. If you receive this email, kindly reply to let me know. \\n\\nThank you ',\n",
       " ' \\nHello, \\n\\nThanks for letting me know the test was successful. Things are going well here. \\n\\nBest, \\n',\n",
       " \" \\n\\nHey there! \\n\\nUnfortunately, I won't be able to make it to drinks after work today, but I'll definitely be there next Thursday for the REAL happy hour. Looking forward to it! \\n\\nOn the 27th, I'm planning to \\n\",\n",
       " \" \\n\\nHi there,\\n\\nThanks for the invite to Bob's Halloween party on the 27th. I'm planning on going, and it will be great to see you there.\\n\\nI'm sorry to hear about your divorce being finalized next Thursday. I'm here for you if you need anything.\\n\\nI'm taking Thursday and Friday off as well, so we can definitely meet up later that day.\\n\\nLooking forward to seeing you soon,\\n\"]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16213f74-698e-4369-a109-0a8aec7aecc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
